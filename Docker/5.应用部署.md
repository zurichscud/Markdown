# MySQL

## 创建容器

```shell
docker run -d -p 3306:3306 \
-v /root/mysql/log:/var/log/mysql \
-v /root/mysql/data:/var/lib/mysql \
-v /root/mysql/conf:/etc/mysql \
-e MYSQL_ROOT_PASSWORD=123456 \
--name mysql \
mysql
```

- -v /usr/local/mysql/log:/var/log/mysql 映射日志目录
-  -v /usr/local/mysql/data:/var/lib/mysql 映射数据目录
-  -v /usr/local/mysql/conf:/etc/mysql 映射配置目录

## 进入MySQL

```shell
docker exec -it mysql bash
```
出现`mysql>`即已进入mysql终端
```sh
#登录mysql
mysql -uroot -p
```

```mysql
show databases;
```

# Redis

## Docker Redis环境

在Docker中，Redis的数据持久化文件存储在`/data`中

appendonly.aof和dump.rdb为AOF持久化和RDB持久化的磁盘文件。

在Docker中没有redis.conf，因此在启动redis server时将会出现报错信息

> Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf

信息表示我们需要指定redis.conf文件路径，一般在Linux中，redis.conf的路径为`/etc/redis/redis.conf`

```
redis-server /etc/redis/redis.conf
```



## 配置redis.conf

在主机中创建/app/redis/redis.conf

```sh
#将bind 127.0.0.1注释
#bind 127.0.0.1
#将yes改为no
daemonize no
```

`daemonize`与docker中的`-d`会发生冲突

修改redis.conf后需要重新启动redis容器才会生效

## 创建容器

没有挂载数据卷操作（**不推荐**）：

```sh
docker run --name redis  --privileged=true -d -p 6379:6379 redis 
```
挂载数据卷操作（**推荐**）：
```sh
docker run -p 6379:6379 \
--name redis \
--privileged=true \
-v /app/redis/redis.conf:/etc/redis/redis.conf \
-v /app/redis/data:/data \
#解决Redis时间不同步问题
 -v /etc/localtime:/etc/localtime:ro \
-d redis \
redis-server /etc/redis/redis.conf

```

```
logfile "/data/redis-server.log"
```



## 进入Redis

```sh
docker exec -it redis6 bash
```

```sh
redis-cli
ping
```

> PONG

# Hadoop

## 3节点集群

使用Guthub项目进行快速部署：https://github.com/zurichscud/hadoop-cluster-docker

1. 下载docker镜像

```sh
docker pull kiwenlau/hadoop:1.0
```

2. 下载项目 https://github.com/zurichscud/hadoop-cluster-docker至Linux主机

- start-container.sh：创建Hadoop容器shell脚本
- resize-cluster.sh：重构N个节点的镜像

3. 创建hadoop网络

```sh
docker network create --driver=bridge hadoop
```

4. 执行git项目中的shell脚本

```sh
./start-container.sh
```

> ```sh
> #运行结果
> start hadoop-master container...
> start hadoop-slave1 container...
> start hadoop-slave2 container...
> root@hadoop-master:~#
> ```

5. 在master容器中执行以下shell脚本启动hadoop集群

```sh
./start-hadoop.sh
```

6. 运行wordcount脚本测试hadoop是否正常运行

```sh
./run-wordcount.sh
```

> ```sh
> #运行结果
> input file1.txt:
> Hello Hadoop
> input file2.txt:
> Hello Docker
> wordcount output:
> Docker	1
> Hadoop	1
> Hello	2
> ```

7. 登录管理端

- NameNode：50070端口
- ResourceManager：8088端口

## N节点集群

**2. 重新构建Docker镜像**

```sh
./resize-cluster.sh 5
```

**3. 启动Docker容器**

```sh
./start-container.sh 5
```

## 文件结构

Hadoop的所有文件都存在于`/usr/local/hadoop`
